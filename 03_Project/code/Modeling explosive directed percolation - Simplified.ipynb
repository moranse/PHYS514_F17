{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of final set-up\n",
    "- Visualization of simple arrays for proof of concept\n",
    "- \n",
    "\n",
    "# To-do\n",
    "- This should mostly work now-- can run up to 1e4 nodes successfully on my laptop\n",
    "- Switching to numpy arrays broke everything-- get everything working again when back on internet\n",
    "    - Use the edge density calculations used in prior versions of this notebook \n",
    "- Once that's finished, go through and see if I can switch the edge density and get interesting results that way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Auto-reloads external files so I can stop re-loading\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "from tools import *\n",
    "import graphs as g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating figures from the paper\n",
    "\n",
    "See notes for metrics.\n",
    "- $\\phi = \\frac{50}{10^6} = 5E-5 = $ fraction of a system that an average node reaches \n",
    "- $m_0=$ average number of edges per node\n",
    "\n",
    "We are better off studying a range of $\\phi=\\frac{m_0}{n}$, as this is more analogous to $p_c$ in percolation lattices.\n",
    "\n",
    "As before, $n$ is the total number of nodes and $m$ is the total number of edges.\n",
    "\n",
    "So our range of behaviors is:\n",
    "- Lower bound: $m_0=1$, $n=2E4$, $m=2E4$\n",
    "- Upper bound (paper): $m_0=50$, $n=1E6$, $m=50E6$\n",
    "- General case: $m_0$, $n=\\frac{m_0}{\\phi}$, $m=m_0{\\cdot}n$\n",
    "\n",
    "In all cases, `edge_density` as defined in the paper is $\\frac{m}{n}$== so just $m_0$.\n",
    "\n",
    "In the paper, when they change the `edge_density`, what they are actually changing is the fraction of the system that any given node is connected to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 5&6\n",
    "\n",
    "I'm able to replicate the shape of these results, my \"edge densities\" are off by a factor of $\\approx 5$. It's not clear to me why this is.\n",
    "\n",
    "The equivalent density at these system sizes is much lower. If anything, I'm actually getting a much higher critical density than I should!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def figure56(process,edge_densities,n):\n",
    "    largest_scc = []\n",
    "    Sample = g.Graph(n,round(edge_densities[0]*n),process)\n",
    "    for density in edge_densities:\n",
    "        Sample.m = round(density*n)\n",
    "        Sample.build()\n",
    "        largest_scc.append(ranked_SCC(tarjan(Sample.edges>0))/n)\n",
    "    return largest_scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot ODER - might have to run outside of a jupyter notebook to get n-10^5 or higher\n",
    "# Running outside of a jupyter notebook still does not solve the problem -- then I run into memory issuees\n",
    "\n",
    "# actual settings in the experiment\n",
    "# n = int(1e6)\n",
    "# phi = np.linspace(1e-6,5e-5,5)\n",
    "\n",
    "# Even 1e4 is now causing my laptop python to crash... not sure what's up with that.\n",
    "n_range = [int(1e3)]\n",
    "edge_densities = np.linspace(1,25,25)\n",
    "replicates = 1\n",
    "\n",
    "for i in range(replicates):\n",
    "    plt.plot(edge_densities,figure56('ODER',edge_densities,n_range[0]))\n",
    "\n",
    "plt.title('Explosive percolation of ODER process')\n",
    "plt.ylabel('Largest SCC')\n",
    "plt.xlabel('Edge density')\n",
    "# plt.legend(labels=n_range)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![fig5](figs/fig5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot C-ODER\n",
    "\n",
    "edge_densities = np.linspace(1,10,20)\n",
    "replicates = 10\n",
    "\n",
    "for i in range(replicates):\n",
    "    plt.plot(edge_densities,figure56('CODER',edge_densities,10**3))\n",
    "\n",
    "plt.title('Explosive percolation of C-ODER process')\n",
    "plt.ylabel('Largest SCC')\n",
    "plt.xlabel('Edge density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot C-ODER\n",
    "\n",
    "edge_densities = np.linspace(1,10,20)\n",
    "replicates = 10\n",
    "\n",
    "for i in range(replicates):\n",
    "    plt.plot(edge_densities,figure56('CODER',edge_densities,10**2))\n",
    "\n",
    "plt.title('Explosive percolation of C-ODER process')\n",
    "plt.ylabel('Largest SCC')\n",
    "plt.xlabel('Edge density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig6](figs/fig6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7\n",
    "\n",
    "Again, in the paper they simulate up to $10^6$ nodes, which is just wildly large. They really didn't need to do this...? Also, what edge density did they use? They don't say. I'm assuming it's 50, because I don't get the same results for other values.\n",
    "\n",
    "![fig7](figs/fig7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def figure7(process,n_sizes,edge_density):\n",
    "    max_jump = []\n",
    "    Sample = g.Graph(n_sizes[0],edge_density*n_sizes[0],process)\n",
    "    for n in n_sizes:\n",
    "        m = round(int(edge_density*n))\n",
    "        Sample.n = n\n",
    "        Sample.m = m\n",
    "        Sample.build()\n",
    "        max_jump.append(get_largest_jump(Sample)/n)\n",
    "    return max_jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting ODER coefficient\n",
    "\n",
    "edge_density = 40\n",
    "\n",
    "systems = np.linspace(1e2,1e3,2).astype(int)\n",
    "# systems = [int(1e3)]\n",
    "# systems = np.linspace(1e2,1e3,3).astype(int)\n",
    "replicates = 5\n",
    "\n",
    "jumps = []\n",
    "for i in range(replicates):\n",
    "    jumps.append(figure7('ODER',systems,edge_density))\n",
    "\n",
    "ODER_jumps_array = np.asarray(jumps).reshape((replicates,len(jumps[0])))\n",
    "ODER_avg_jump= np.mean(ODER_jumps_array, axis=0)\n",
    "ODER_std_jump= np.std(ODER_jumps_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(systems,ODER_avg_jump,yerr=ODER_std_jump, fmt='o')\n",
    "# plt.axis([0,max(systems)*1.1,-0.05,0.20])\n",
    "plt.title('Max jump size, ODER')\n",
    "plt.ylabel('Max jump')\n",
    "plt.xlabel('System size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting CODER coefficient\n",
    "\n",
    "systems = np.linspace(5e2,1e4,2).astype(int)\n",
    "# systems = [int(1e3)]\n",
    "# systems = np.linspace(5e2,1e4,5).astype(int)\n",
    "replicates = 2\n",
    "\n",
    "CODER_jumps = []\n",
    "for i in range(replicates):\n",
    "    CODER_jumps.append(figure7('CODER',systems,edge_density))\n",
    "\n",
    "CODER_jumps_array = np.asarray(CODER_jumps).reshape((replicates,len(CODER_jumps[0])))\n",
    "CODER_avg_jump= np.mean(CODER_jumps_array, axis=0)\n",
    "CODER_std_jump= np.std(CODER_jumps_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(systems,CODER_avg_jump,yerr=CODER_std_jump, fmt='o')\n",
    "# plt.axis([0,max(systems)*1.1,-0.05,0.20])\n",
    "plt.title('Max jump size, C-ODER')\n",
    "plt.ylabel('Max jump')\n",
    "plt.xlabel('System size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "array = g.Graph(int(1e4),int(5e5),'ODER')\n",
    "array.build()\n",
    "print(array.edges.shape)\n",
    "# Image.fromarray(array.edges,mode='L')\n",
    "plt.imshow(array.edges,cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 8\n",
    "\n",
    "Again, this spot-on replicates the finding that the C-ODER process jump comes from the combination of two large components combining-- but the critical edge density is off by a factor of 5! \n",
    "\n",
    "![fig8](figs/fig8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this works up to 1e4\n",
    "def figure8(process,edge_densities):\n",
    "    n = int(1e4)\n",
    "    first_scc,second_scc,third_scc = [],[],[]\n",
    "    Sample = g.Graph(n,1,'CODER')\n",
    "    for density in edge_densities:\n",
    "        m = density*n\n",
    "        Sample.m = m\n",
    "        Sample.build()\n",
    "        first_scc.append(ranked_SCC(tarjan(Sample.edges),rank=1)/n)\n",
    "        second_scc.append(ranked_SCC(tarjan(Sample.edges),rank=2)/n)\n",
    "        third_scc.append(ranked_SCC(tarjan(Sample.edges),rank=3)/n)\n",
    "    return first_scc, second_scc, third_scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge_densities = np.linspace(1,20,10)\n",
    "first_scc, second_scc, third_scc = figure8('CODER',edge_densities)\n",
    "\n",
    "plt.scatter(edge_densities,first_scc,label=\"Largest SCC\")\n",
    "plt.scatter(edge_densities,second_scc,label=\"Second largest SCC\")\n",
    "plt.scatter(edge_densities,third_scc,label=\"Third largest SCC\")\n",
    "plt.title('SCC combination near critical edge density in a C-ODER graph')\n",
    "plt.ylabel('Component size')\n",
    "plt.xlabel('Edge density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 9\n",
    "Interesting, but low priority until other issues are worked out.\n",
    "\n",
    "![fig9](figs/fig9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
