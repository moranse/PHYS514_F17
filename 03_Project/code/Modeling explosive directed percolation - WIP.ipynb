{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For discussion with Prof Gull\n",
    "- Need to make this faster, ideas:\n",
    "    - Pool/multiprocessing\n",
    "- I can replicate all the plots, but the scale is wrong...\n",
    "- Next steps:\n",
    "    - Any ideas why my scale might be off? Consider reaching out to authors?\n",
    "    - Comparing this with ER, networkx, showing how Newman-Ziff works?\n",
    "    \n",
    "Boost library for graphs: http://www.boost.org/doc/libs/1_65_1/libs/graph/doc/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics 514, Fall 2017: Studying explosive percolation on directed networks\n",
    "\n",
    "Outline for report:\n",
    "- Background\n",
    "    - Phys 514 concepts: Percolation, critical point, critical exponents\n",
    "    - Why is explosive percolation different?\n",
    "    - Network theory background:\n",
    "        - Networks: Directed v undirected, ordered v unordered, classical graphs (Erdos-Renyi)\n",
    "        - Clustering: For directed networks, study the strongest connected component, SCC (define)\n",
    "        - Clustering algorithms: Hoshen-Kopelman won't work here; Newman-Ziff for undirected networks, Tarjan's Algorithm (implemented here) for finding the SCC of directed networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "import time\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import random\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for graphs\n",
    "\n",
    "*Consider adding these into the class later.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_if_edge_exists(proposed,edges):\n",
    "    for item in edges:\n",
    "        if proposed==item: return True\n",
    "        else: pass\n",
    "\n",
    "def edges_to_viz(edges,n):\n",
    "        viz_array = np.zeros((n,n))\n",
    "        for i in edges:\n",
    "            viz_array[i[0],i[1]]+=1\n",
    "        return viz_array\n",
    "\n",
    "def edges_to_children(edges):\n",
    "    children = defaultdict(list)\n",
    "    for u,v in edges:\n",
    "        children[u].append(v)\n",
    "    return children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "  \n",
    "    def __init__(self,n,m,process_name):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "        self.edge_density = m/n\n",
    "        self.edges = []\n",
    "        self.adjacency_matrix = np.zeros((n,n))\n",
    "        self.nodes = 0\n",
    "        self.LJ = 0       \n",
    "        self.process = process_name \n",
    "        \n",
    "    def initialize(self):\n",
    "        if self.process=='CODER': self.CODER()\n",
    "        elif self.process==\"ODER\": self.ODER()\n",
    "        else: print('initialize with a valid process')\n",
    "    \n",
    "    def add_edge(self,p):\n",
    "        if self.adjacency_matrix[p[0],p[1]]:\n",
    "            if self.adjacency_matrix[p[1],p[0]]: pass\n",
    "            else: self.adjacency_matrix[p[1],p[0]] = 1; self.nodes+=1\n",
    "        else: self.adjacency_matrix[p[0],p[1]]=1; self.nodes+=1\n",
    "    \n",
    "    def add_edge_OLD(self,proposed_edge):\n",
    "        if check_if_edge_exists(proposed_edge,self.edges):\n",
    "            if check_if_edge_exists(tuple(reversed(proposed_edge)),self.edges): pass\n",
    "            else: self.edges.append(tuple(reversed(proposed_edge)))\n",
    "        else: self.edges.append(proposed_edge)\n",
    "\n",
    "    def ODER(self):\n",
    "        # set up list of nodes with ranked order\n",
    "        n_list = np.linspace(0,self.n-1,self.n).astype(int)\n",
    "        # add m edges to the plot\n",
    "#         while len(self.edges)<self.m:\n",
    "        pbar = tqdm_notebook(total=(self.m-self.nodes),desc=\"Implementing ODER process\")\n",
    "        while self.nodes<self.m:\n",
    "            first_node, second_node = random.sample(list(n_list),2)\n",
    "            proposed_edge = tuple(sorted((first_node,second_node)))\n",
    "            n0 = self.nodes\n",
    "            self.add_edge(proposed_edge)\n",
    "            pbar.update(self.nodes-n0)\n",
    "        pbar.close()\n",
    "            \n",
    "    def CODER(self):\n",
    "        # set up list of nodes with ranked order\n",
    "        n_list = np.linspace(0,self.n-1,self.n).astype(int)\n",
    "        while len(self.edges)<self.m:\n",
    "            first_node, second_node, third_node = random.sample(list(n_list),3)\n",
    "            proposed_edges = tuple(itertools.combinations(tuple(sorted((first_node,second_node,third_node))), 2))\n",
    "\n",
    "            # for nodes with min difference, check if they/their reverse already exist; if no, add them\n",
    "            difference = np.asarray([nodes[1]-nodes[0] for nodes in proposed_edges])\n",
    "            idx = np.where(difference == difference.min())[0]\n",
    "            for i in idx:\n",
    "                proposed_edge = proposed_edges[i]\n",
    "                self.add_edge(proposed_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the strongest connected component using Tarjan's Algorithm\n",
    "\n",
    "[notes to be cleaned up]\n",
    "\n",
    "Paper reference: [https://doi.org/10.1137/0201010](https://doi.org/10.1137/0201010)\n",
    "\n",
    "![here](https://upload.wikimedia.org/wikipedia/commons/6/60/Tarjan%27s_Algorithm_Animation.gif)\n",
    "\n",
    "From Wikipedia:\n",
    "- A depth-first search begins from an arbitrary start node\n",
    "- subsequent depth-first searches are conducted on any nodes that have not yet been found\n",
    "- As usual with depth-first search, the search visits every node of the graph exactly once, declining to revisit any node that has already been visited\n",
    "- => the collection of search trees is a spanning forest of the graph\n",
    "\n",
    "While going through the nodes:\n",
    "- Nodes are placed on a stack in the order in which they are visited\n",
    "- A node remains on the stack after it has been visited if and only if there exists a path in the input graph from it to some node earlier on the stack\n",
    "- At the end of the call that visits v and its descendants, we know whether v itself has a path to any node earlier on the stack. \n",
    "    - If yes, the call returns, leaving v on the stack to preserve the invariant\n",
    "    - If no, then v must be the root of its strongly connected component, which consists of v together with any nodes later on the stack than v (such nodes all have paths back to v but not to any earlier node, because if they had paths to earlier nodes then v would also have paths to earlier nodes which is false)\n",
    "\n",
    "Book-keeping:\n",
    "- Each node v is assigned:\n",
    "    - a unique integer v.index, which numbers the nodes consecutively in the order in which they are discovered\n",
    "    - a value v.lowlink that represents (roughly speaking) the smallest index of any node known to be reachable from v, including v itself\n",
    "- Conditions:\n",
    "    - if v.lowlink < v.index, leave v on stack\n",
    "    - if v.lowlink == v.index, v must be removed as the root of a strongly connected component\n",
    "- Calculating: The value v.lowlink is computed during the depth-first search from v, as this finds the nodes that are reachable from v.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to rewrite this to be more user-friendly\n",
    "def tarjan_OLD(neighbors):  \n",
    "        index_counter = [0]\n",
    "        index = {}\n",
    "        lowlink = {}\n",
    "        stack = []\n",
    "\n",
    "        result = []\n",
    "\n",
    "        # v is node-- wait, but shouldn't it actually be u...?\n",
    "        def calc_component(node):\n",
    "            # v.index, v.lowlink\n",
    "            index[node] = index_counter[0]\n",
    "            lowlink[node] = index_counter[0]\n",
    "            index_counter[0] += 1\n",
    "            stack.append(node)\n",
    "\n",
    "            # find the children\n",
    "            try:\n",
    "                children = neighbors[node]\n",
    "            except:\n",
    "                children = []\n",
    "            for child in children:\n",
    "                # if the child hasn't been visited, run this on it\n",
    "                print(lowlink)\n",
    "                if child not in lowlink:\n",
    "                    calc_component(child)\n",
    "                    lowlink[node] = min(lowlink[node],lowlink[child])\n",
    "                # if the child is in the stack, that means they're also in the SCC\n",
    "                elif child in stack:\n",
    "                    lowlink[node] = min(lowlink[node],index[child])\n",
    "\n",
    "            if lowlink[node]==index[node]:\n",
    "                connected_component = []\n",
    "                while True:\n",
    "                    successor = stack.pop()\n",
    "                    connected_component.append(successor)\n",
    "                    if successor == node: break\n",
    "                component = tuple(connected_component)\n",
    "                # storing the result\n",
    "                result.append(component)\n",
    "\n",
    "        for node in list(neighbors):\n",
    "            if node not in lowlink:\n",
    "                calc_component(node)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to rewrite this to be more user-friendly\n",
    "def tarjan(adjacency_matrix):  \n",
    "        index_counter = [0]\n",
    "        index = {}\n",
    "        lowlink = {}\n",
    "        stack = []\n",
    "\n",
    "        result = []\n",
    "\n",
    "        # v is node-- wait, but shouldn't it actually be u...?\n",
    "        def calc_component(node):\n",
    "            # v.index, v.lowlink\n",
    "            index[node] = index_counter[0]\n",
    "            lowlink[node] = index_counter[0]\n",
    "            index_counter[0] += 1\n",
    "            stack.append(node)\n",
    "\n",
    "            # find the children\n",
    "            try:\n",
    "                children = np.where(adjacency_matrix[node,:]==1)[0]\n",
    "#                 print(children)\n",
    "            except:\n",
    "                children = []\n",
    "            for child in children:\n",
    "                # if the child hasn't been visited, run this on it\n",
    "                if child not in lowlink:\n",
    "                    calc_component(child)\n",
    "                    lowlink[node] = min(lowlink[node],lowlink[child])\n",
    "                # if the child is in the stack, that means they're also in the SCC\n",
    "                elif child in stack:\n",
    "                    lowlink[node] = min(lowlink[node],index[child])\n",
    "\n",
    "            if lowlink[node]==index[node]:\n",
    "                connected_component = []\n",
    "                while True:\n",
    "                    successor = stack.pop()\n",
    "                    connected_component.append(successor)\n",
    "                    if successor == node: break\n",
    "                component = tuple(connected_component)\n",
    "                # storing the result\n",
    "                result.append(component)\n",
    "\n",
    "        for node in range(adjacency_matrix.shape[0]):\n",
    "            if node not in lowlink:\n",
    "                calc_component(node)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement search function for jumps from paper\n",
    "\n",
    "This paper is particularly intreested in finding the explosive percolation phase transition.\n",
    "\n",
    "While in our classic lattice percolation models, this was a matter of finding $p_c$, here it's going to be an edge density, $\\delta=\\frac{m}{n}$ where $m$ is the number of edges and $n$ is the number of nodes.\n",
    "\n",
    "Instead of calculating the SCC every time an edge is added, it builds the completed graph then performs a binary search to find the edge addition at which the largest jump-- the percolation transition-- occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ranked_SCC(connected_components,rank=1):\n",
    "    C = []\n",
    "    for members in connected_components:\n",
    "        C.append(len(members))\n",
    "    if rank>len(C): return 0\n",
    "    return sorted(C)[-rank]\n",
    "\n",
    "def binary_search(graph,start,end,LJ):\n",
    "    midpoint = int(round((start+end)/2))\n",
    "    head = ranked_SCC(tarjan(edges_to_children(graph.edges[0:start+1])))\n",
    "    mid = ranked_SCC(tarjan(edges_to_children(graph.edges[0:midpoint])))\n",
    "    tail = ranked_SCC(tarjan(edges_to_children(graph.edges[0:end])))\n",
    "    if abs(end-start)==1:\n",
    "        if (tail-head)>LJ: LJ = (tail-head)\n",
    "        return LJ\n",
    "    elif (mid-head)>(tail-mid):\n",
    "        if (mid-head)>(graph.n/100):\n",
    "            LJ = (mid-head)\n",
    "            return binary_search(graph,start,midpoint,LJ)\n",
    "    elif (tail-mid)>(graph.n/100):\n",
    "        LJ = (tail-mid)\n",
    "        return binary_search(graph,midpoint,end,LJ)\n",
    "    return LJ\n",
    "\n",
    "def get_largest_jump(graph):\n",
    "    start = 0\n",
    "    midpoint = int(round(graph.m/2))\n",
    "    end = graph.m-1\n",
    "#     print(start,midpoint,end)\n",
    "    head = ranked_SCC(tarjan(edges_to_children(graph.edges[start:start+1])))\n",
    "    mid = ranked_SCC(tarjan(edges_to_children(graph.edges[start:midpoint])))\n",
    "    tail = ranked_SCC(tarjan(edges_to_children(graph.edges[start:end])))\n",
    "    LJ = 0\n",
    "    if (tail-head)<(graph.n/100): return jump\n",
    "    elif (mid-head)>(graph.n/100):\n",
    "        jump = binary_search(graph,start,midpoint,LJ)\n",
    "    elif (tail-mid)>(graph.n/100):\n",
    "        jump = binary_search(graph,midpoint,end,LJ)\n",
    "    return jump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the percolation processes \n",
    "\n",
    "The paper does an edge density of up to 50, with $10^6$ nodes.\n",
    "\n",
    "The way the paper defines edge density is\n",
    "$$\\delta = \\frac{m}{n}$$\n",
    "where $m$ is the number of directed edges on the graph, and $n$ is the number of nodes. An edge density of 50 implies that each site has 50 neighbors, which is really dense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n = 10^4 and edge_density = 50 takes 4 min to run\n",
    "n = 10**4\n",
    "edge_density = 5e-5*n\n",
    "m = edge_density*n\n",
    "# CODER_test = Graph(n,m,'CODER')\n",
    "ODER_test = Graph(n,m,'ODER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "5000.0\n"
     ]
    }
   ],
   "source": [
    "print(ODER_test.nodes)\n",
    "print(ODER_test.nodes/ODER_test.m)\n",
    "print(ODER_test.m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running 10^4 nodes takes ~3 seconds (m=5k)\n",
    "- Running 5x10^4 nodes takes ~1 min (m=125k)\n",
    "- Running 10^5 nodes should take ~30 minutes (woof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CODER_test.initialize()\n",
    "ODER_test.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10**2\n",
    "p = 50/n\n",
    "er = nx.erdos_renyi_graph(n,p,directed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing networks of 100 nodes using a graph, especially at an edge density of 50, is likely to be a mess-- and not easy to do. The paper does not attempt to show graphs for their findings, beyond illustrative graphs of their processeds.\n",
    "\n",
    "Instead, I steal the idea of how co-variance matrices are sometimes shown, and convert the edges of the graph to a binary yes/no edges array. This will show biases in my networks-- e.g. if there are no or fewer reverse edges, the lower traingle of the edge array will be sparser. This is indeed what we see for ODER and C-ODER, which have a preferential ordering rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# er_viz = edges_to_viz(er.edges(),n)\n",
    "\n",
    "# plt.imshow(er_viz,cmap='binary')\n",
    "# plt.title('Erdos-Renyi stochastic graph for comparison')\n",
    "# plt.ylabel('tail')\n",
    "# plt.xlabel('head')\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# ODER_viz = edges_to_viz(ODER_test.edges,ODER_test.n)\n",
    "\n",
    "plt.imshow(ODER_test.adjacency_matrix,cmap='binary')\n",
    "plt.title('ODER simulation')\n",
    "plt.ylabel('tail')\n",
    "plt.xlabel('head')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# CODER_viz = edges_to_viz(CODER_test.edges,CODER_test.n)\n",
    "\n",
    "# plt.imshow(CODER_viz,cmap='binary')\n",
    "# plt.title('CODER simulation')\n",
    "# plt.ylabel('tail')\n",
    "# plt.xlabel('head')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating figures from the paper\n",
    "\n",
    "I wonder if I also need to change the edge density, since I'm not using the same number of nodes.\n",
    "\n",
    "Maybe the better metric is, what % of all other nodes is each node connected to, on average?\n",
    "\n",
    "If $\\delta=50$ for $n=10^6$, then each node is on average connected to $\\frac{50}{10^6}=5e-5$ of the rest of the system.\n",
    "\n",
    "So for a system of size $n$, we can set an equivalent density with $\\frac{\\delta}{n}=5e-5$.\n",
    "\n",
    "Then the total number of edges in the system are $m={\\delta}n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1000.   112000.   223000.   334000.   445000.   556000.   667000.\n",
      "   778000.   889000.  1000000.]\n",
      "[  0.05   5.6   11.15  16.7   22.25  27.8   33.35  38.9   44.45  50.  ]\n",
      "[  5.00000000e+01   6.27200000e+05   2.48645000e+06   5.57780000e+06\n",
      "   9.90125000e+06   1.54568000e+07   2.22444500e+07   3.02642000e+07\n",
      "   3.95160500e+07   5.00000000e+07]\n"
     ]
    }
   ],
   "source": [
    "n = np.linspace(1000,10**6,10)\n",
    "equiv_densities = n*(5*10**(-5))\n",
    "m = equiv_densities*n\n",
    "print(n)\n",
    "print(equiv_densities)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 5&6\n",
    "\n",
    "I'm able to replicate the shape of these results, my \"edge densities\" are off by a factor of $\\approx 5$. It's not clear to me why this is.\n",
    "\n",
    "The equivalent density at these system sizes is much lower. If anything, I'm actually getting a much higher critical density than I should!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def matrix_to_dict(graph):\n",
    "    children = defaultdict(list)\n",
    "    for u in range(ODER_test.adjacency_matrix.shape[0]):\n",
    "        child = np.where(ODER_test.adjacency_matrix[u]==1)[0].tolist()\n",
    "        children[u].append(child)\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def figure56(process,edge_densities,n):\n",
    "    largest_scc = []\n",
    "    Sample = Graph(n,0,process)\n",
    "    for density in edge_densities:\n",
    "        Sample.m = density*n\n",
    "        Sample.initialize()\n",
    "#         largest_scc.append(ranked_SCC(tarjan(edges_to_children(Sample.edges)))/n)\n",
    "#         largest_scc.append(ranked_SCC(tarjan(matrix_to_dict(Sample.adjacency_matrix)))/n)\n",
    "        largest_scc.append(ranked_SCC(tarjan(Sample.adjacency_matrix))/n)\n",
    "    return largest_scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  10000.           64444.44444444  118888.88888889  173333.33333333\n",
      "  227777.77777778  282222.22222222  336666.66666667  391111.11111111\n",
      "  445555.55555556  500000.        ]\n"
     ]
    }
   ],
   "source": [
    "# Plot ODER - might have to run outside of a jupyter notebook to get n-10^5 or higher\n",
    "\n",
    "replicates = 1\n",
    "n = 10**5\n",
    "edge_density = 5e-5*n\n",
    "\n",
    "# edge_densities = np.linspace(0.1*edge_density,edge_density,10)\n",
    "# edge_densities = np.linspace(1,50,20)\n",
    "edge_densities = np.linspace(10**(-6)*n,5*10**(-5)*n,10)\n",
    "m = edge_densities*n\n",
    "print(m)\n",
    "\n",
    "for i in range(replicates):\n",
    "    plt.plot(edge_densities,figure56('ODER',edge_densities,n))\n",
    "plt.title('Explosive percolation of ODER process')\n",
    "plt.ylabel('Largest SCC')\n",
    "plt.xlabel('Edge density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig5](figs/fig5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot C-ODER\n",
    "\n",
    "replicates = 10\n",
    "edge_densities = np.linspace(1,10,20)\n",
    "for i in range(replicates):\n",
    "    plt.plot(edge_densities,figure56('CODER',edge_densities))\n",
    "plt.title('Explosive percolation of C-ODER process')\n",
    "plt.ylabel('Largest SCC')\n",
    "plt.xlabel('Edge density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig6](figs/fig6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7\n",
    "\n",
    "Again, in the paper they simulate up to $10^6$ nodes, which is just wildly large.\n",
    "\n",
    "![fig7](figs/fig7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def figure7(process,n_sizes):\n",
    "    edge_density = 10\n",
    "    max_jump = []\n",
    "    Sample = Graph(1,1,process)\n",
    "    for n in n_sizes:\n",
    "        m = edge_density*n\n",
    "        Sample.n = n\n",
    "        Sample.m = m\n",
    "        Sample.initialize()\n",
    "        max_jump.append(get_largest_jump(Sample)/n)\n",
    "    return max_jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting C-ODER coefficient\n",
    "\n",
    "systems = np.linspace(500,1000,5).astype(int)\n",
    "replicates = 15\n",
    "jumps = []\n",
    "for i in range(replicates):\n",
    "    jumps.append(figure7('CODER',systems))\n",
    "\n",
    "CODER_jumps_array = np.asarray(jumps).reshape((replicates,len(jumps[0])))\n",
    "CODER_vg_jump= np.mean(CODER_jumps_array, axis=0)\n",
    "CODER_std_jump= np.std(CODER_jumps_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(systems,CODER_vg_jump,yerr=CODER_std_jump, fmt='o')\n",
    "# plt.axis([0,max(systems)*1.1,-0.05,0.20])\n",
    "plt.title('Max jump size, C-ODER')\n",
    "plt.ylabel('Max jump')\n",
    "plt.xlabel('System size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting ODER coefficient\n",
    "\n",
    "systems = np.linspace(500,1000,5).astype(int)\n",
    "replicates = 15\n",
    "jumps = []\n",
    "for i in range(replicates):\n",
    "    jumps.append(figure7('ODER',systems))\n",
    "\n",
    "ODER_jumps_array = np.asarray(jumps).reshape((replicates,len(jumps[0])))\n",
    "ODER_avg_jump= np.mean(ODER_jumps_array, axis=0)\n",
    "ODER_std_jump= np.std(ODER_jumps_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.errorbar(systems,ODER_avg_jump,yerr=ODER_std_jump, fmt='o')\n",
    "# plt.axis([0,max(systems)*1.1,-0.05,0.20])\n",
    "plt.title('Max jump size, ODER')\n",
    "plt.ylabel('Max jump')\n",
    "plt.xlabel('System size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 8\n",
    "\n",
    "Again, this spot-on replicates the finding that the C-ODER process jump comes from the combination of two large components combining-- but the critical edge density is off by a factor of 5! \n",
    "\n",
    "![fig8](figs/fig8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def figure8(process,edge_densities):\n",
    "    n = 10**2\n",
    "    first_scc,second_scc,third_scc = [],[],[]\n",
    "    Sample = Graph(n,1,'CODER')\n",
    "    for density in edge_densities:\n",
    "        m = density*n\n",
    "        Sample.m = m\n",
    "        Sample.initialize()\n",
    "        first_scc.append(ranked_SCC(tarjan(edges_to_children(Sample.edges)),rank=1)/n)\n",
    "        second_scc.append(ranked_SCC(tarjan(edges_to_children(Sample.edges)),rank=2)/n)\n",
    "        third_scc.append(ranked_SCC(tarjan(edges_to_children(Sample.edges)),rank=3)/n)\n",
    "    return first_scc, second_scc, third_scc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edge_densities = np.linspace(1,10,20)\n",
    "first_scc, second_scc, third_scc = figure8('CODER',edge_densities)\n",
    "\n",
    "plt.scatter(edge_densities,first_scc,label=\"Largest SCC\")\n",
    "plt.scatter(edge_densities,second_scc,label=\"Second largest SCC\")\n",
    "plt.scatter(edge_densities,third_scc,label=\"Third largest SCC\")\n",
    "plt.title('SCC combination near critical edge density in a C-ODER graph')\n",
    "plt.ylabel('Component size')\n",
    "plt.xlabel('Edge density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 9\n",
    "Interesting, but low priority until other issues are worked out.\n",
    "\n",
    "![fig9](figs/fig9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
